\section{Causality as Effect Propagation Process}
\label{sec:epp}

The foundational premise of the EPP is the detachment of causality from a presupposed spacetime. This premise necessitates a re-evaluation of the causal relation itself, shifting its conceptualization to a more general process of effect propagation. From this re-evaluation, the core architectural components of the EPP, are derived. The theoretical foundations of the EPP results from a multi-disciplinary background. 

%
% Background
%
\subsection{Background}
\label{sec:epp_background}

The Effect Propagation Process (EPP) builds upon a confluence of ideas from process philosophy, modern physics, and contemporary machine learning. Its conception follows a progression from a core philosophy to a specific architecture that addresses contemporary computational challenges.

The EPP's primary departure point is a fundamental rejection of the classical Newtonian conception of a static, absolute background spacetime. This move is deeply rooted in the tradition of process philosophy, which argues that reality is not composed of enduring, static substances but is a dynamic flow of interconnected events. This idea finds its clearest expression in the work of Alfred North Whitehead, who posited a universe of "actual occasions"\cite{whitehead2010process}, and Henri Bergson, who described reality as a continuous "creative evolution"\cite{bergson2022creative}. Their shared insight of reality as a process inspires the EPP's foundational redefinition of causality itself, shifting from a static, happen-before relation to a dynamic process of effect propagation.

The EPP is inspired by Einstein's theory of General Relativity\cite{EinsteinPapers1915}, which demonstrated that spacetime is a dynamic fabric, its geometry determined by the matter within it, which in turn dictates the motion of matter. The EPP's concept of a Contextual Relativity that is both influenced by and influences the entities within is a direct metaphysical analogue of this profound physical insight. 

Luciano Floridi's view\cite{floridi2025applied} that the design principles for  dynamic systems require a relational paradigm was profoundly inspirational to the formalization of the Effect Propagation Process. The EPP leverages the hypergraph as its foundational structure to model rich and complex causality through relationships. 

 Bernhard Schölkopf\cite{binkyte2025causalitykeyunderstandbalance} advocates that integrating causal methods into machine learning helps to navigate fairness, privacy, robustness, accuracy, and explainability. He argues that  a causal approach is essential for balancing multiple competing objectives and, ideally, these objectives should ideally be satisfied simultaneously. The EPP embraces his line of reasoning and takes a principled integrated stance as a result.  
 
Lucian Hardy introduced the "causaloid,"\cite{HardyDynamicCausalStructure} a concept that encapsulates a spatial region and the causal connections within  as foundation his work on finding a theory of Quantum Gravity. Critically, unlike all prior forms of causality, Hardy's causaloid is spacetime agonistic because it folds cause and effect into one entity and thus removes the need for temporal order. The EPP draws direct inspiration from Hardy’s pioneering work by using the term Causaloid honoring Hardy's concept of a unified, self-contained unit of causality, though it has been adapted for a more general, computational context. However, to operationalize spacetime agnostic causality, a new definition of causality became necessary. 

 
%
% Definitions
%
\subsection{Definition}
\label{sec:epp_definition}

The notion of a generative process that underlies the fabric of spacetime leads to the implication that causality has to evolve beyond the strict “before-after” relation towards a spacetime-agnostic view. The classical definition of causality, taken from Judea Pearl's foundational work\cite{pearl2000causality}: 

\begin{quote}
    IF (cause) A then (effect) B.
    
    AND 
    
    IF NOT (cause) A, then NOT (effect) B.
\end{quote}

When removing temporal order from causality, it is indeed no longer possible to discern cause from effect because, in the absence of time, there is no “happen-before” relation any longer, and therefore, the designation of cause or effect indeed becomes infeasible, just as Russell hinted at earlier on. When removing space from causality, the location of a cause or effect in space is not possible anymore because space itself is no longer available. 

\newpage

The absence of spacetime raises the question: \textit{What is the essence of causality?}

Logically, the answer comes in three parts:

\begin{enumerate}
    \item Causality is a process.
    \item Causality determines effects.
    \item Causality describes how effects propagate.
\end{enumerate}


The first one is self-explanatory because causality occurs in dynamic systems that change and therefore, causality must be a process. The idea goes back to Whitehead, has been further developed by Bergson, and finds precedent in Mill's method of concomitant variation\cite{mill2023system}.  

The second one is less obvious, because one might think that causality is all about the “cause” that brings the effects into existence. However, let’s think the other way around: We know that X is the cause of effect E, because E happens when X happens and because E does not happen when X does not happen either. Therefore, we can determine a cause in terms of its effects. An effect, in essence, is an observable change of state. Therefore, it is true that causality determines effects.

The third one, effect propagation, needs elaboration because it is commonly assumed that the cause is the dominant factor in causality. When we rewrite the previous definition of classical causality in terms of effect propagation, however, we see that there is no loss of information:

\begin{quote}
    If X happens, then its effect propagates to Effect E.

    AND
    
    If X does not happen, then its effect does not propagate to Effect E.
\end{quote}

In this definition, X does not have a designated label and instead is described in terms of its emitting effect. Therefore, X can be seen as a preceding effect, which then propagates its effect further. Thus, we can write without loss of information:


\begin{quote}
	If Effect E1 happens, then its effect propagates to Effect E2.

    AND
    
	If Effect E1 does not happen, then its effect does not propagate to Effect E2.
\end{quote}

Therefore, causality becomes an effect propagation process. The effect propagation process definition is more general and treats the classical happen-before definition of causality as a specialized derived form. When the preceding effect is designated as a “cause”, then you can rewrite the general definition back into the classical definition of causality therefore the generalized and the specialized definition of causality remain congruent. The EPP formalizes the 'effect' itself as a dedicated 'PropagatingEffect' together with supporting formalism to operationalize the effect propagation process. 

% 
% Overview
%
\subsection{Overview of the EPP}
\label{sec:epp_overview}

The starting point of the EPP is a generalized definition of causality as effect propagation, which detaches the concept from a pre-supposed spacetime. From the generalized definition of causality, a cascade of novelties followed to operationalize the EPP:

%
% TODO: Make this congruent with the subsequent sub sections of the EPP
%
\begin{enumerate}
	\item Explicite Assumptions 
	\item Externalized, Computable Context
	\item Unified Causal Unit
	\item Fractal, Self-Referential Causal Structure
	\item Multi Modal Propagating Effect
	\item Causal State Machine 
\end{enumerate}

\newpage

\textbf{Explicit Assumption:}

The EPP defines a "Model" as a set that comprises of a the core logic encapsulated in one or more causaloids, one or more contexts used by the causaloids, and a set of explicit assumption that must hold true for the model to work. Conventionally, in classical causality, assumptions about the data are  implicit and the decision whether a causal model can be transferred to a different data dataset requires additional methods such as Invariant Causal Prediction (ICP) to determine if a causal model applies to a dataset with a different distribution. In contrast, the EPP elevates assumptions as a first class entity that serves the purpose to decide upon model transferability by encoding assumptions into explicitly testable and computable units. 

\textbf{An Externalized, Computable Context:} 

The detachment from a fixed spacetime necessitates the externalization of the environment into a first-class Context. This Context is a rich and explicit representation of the world that the Causaloids read from and reason about. A context may be a static representation of facts, a complex multi-scale temporal graph, a complex coordinate system, or any combination thereof. A static context emits an invariant structure after it’s defined whereas in a dynamic context, the context structure itself evolves e.g. new elements are added or remove. In both cases, elements of a context can be adjusted and updated to reflect either new values or correction of existing values. The adjustment mechanism allows for error correction or the adjustment for relativistic effects.   

 \textbf{Unified Causal Unit:} 
 
 The EPP resolves the untenability of the classical 'cause-effect' separation by introducing the Causaloid. The Causaloid is a single, computable entity that unifies the mechanism of a cause with its effect. The Causaloid comprises of a causal function and therefore establishes function theory and the related lambda calculus as the foundation for causality in the EPP. 

\textbf{Fractal, Self-referential Causal Structure:} 

The EPP inverts the classical relationship between a causal unit and its environment. In classical models, the causal structure is a pre-defined framework (such as a DAG) in which entities are placed. The EPP establishes a fundamentally entity-first, fractal and self-referential definition of causality by defining the structure as relationships between causaloids and causaloids as the elements of the relationships. This mechanism is made operational through isomorphic recursive composition. The EPP establishes three distinct forms of causaloids that are all isomorphic, yet distinct: Singleton, Collection, Graph.  The isomorphism allows a single Causaloid node to represent either a single causaloid, a collection of causaloids, or to encapsulate an entire, arbitrarily complex Causaloid Graph, enabling the concise expression of deeply layered systems. The collection exists as a specialized form of the graph to simplify common use cases without the complexity of a graph structure. 


\textbf{Multi Modal Propagating Effect:}
  
To facilitate reasoning within the causal structure, the EPP unifies causal input (Evidence) and output (Effect) into a single, isomorphic type: the PropagatingEffect. The Causaloids unifies cause and effect into one logical unit and the EPP is achieving this by formulating the Causaloid as a higher order function, one that encapsulates a causal function and applies to data for reasoning. As a direct consequence, the distinction between causal input and output becomes quite arbitrary considering that the output of one causaloid is expected to be applied to another causaloid. Therefore, the deliberate decision was made to follow the same logic of the causaloid and fold causal input (Evidence) and output (Effect) into a single, isomorphic type that uniformly represent both and thus directly enable the application of causal output from one causaloid as causal input to another causaloid. This provides a single type that enables the principled unification of deterministic and probabilistic reasoning across arbitrary complex causal structures. 
 

\textbf{Causal State Machine:}

The EPP bridges the gap between causal reasoning and intervention with the causal state machine (CSM). The CSM uses a causal state that connects to the reasoning outcome via the  PropagatingEffect and ultimately converts all complex reasoning into a binary outcome to indicate whether to act according to the defined causal action. When the causal state of a CSM evaluates to true, it then fires its causal action. The action is a regular function that may interact with the context, the causal model, or any external system. The clear separation between context, causal logic, and intervention has been designed for regulatory reasons. In regulated industries, an auditable trail for each action is legally required  and by making the causal reasoning fully explainable before deciding upon an intervention directly supports internal auditing and external regulatory reporting.   

\newpage

%
% Assumption
%
\subsection{Explicit Assumptions}
\label{sec:assumptions}
 
 In the EPP, model assumptions are explicit and connected to the model.  In practice, this allows to define a Model with a set of preconditions (the
  assumptions). Before using the model for reasoning or prediction, this allows to efficiently check if all its underlying
  assumptions hold true for the given data, ensuring the model is operating within its  valid parameters. Furthermore, transferring a model to a new environment can be
  tested by sampling representative data and testing the samples against the model assumptions to gauge if a model transfer is feasible. In practice, even if an assumption test is positive, it is advised to test the model with an alternate context that closely resembles the new environment to gain more confidence in the degree of transferability. 
 
%
% Context
%
\subsection{Context}
\label{sec:epp_context}

A key contribution of the EPP is the externalization of context as a first-class entity.
The context of a causal model is a hypergraph, that encapsulates supporting data. 
Each node in this hypergraph is a Contextoid, a unit of information that can represent:

\begin{itemize}
	\item Data
	\item Time, Space, and Spacetime
	\item Symbol 
\end{itemize}

The causal logic is kept distinct from the contextual data it operates on. It also directly enables the  agnosticism to the structure of space and time, accommodating Euclidean, non-Euclidean, and symbolic representations within the same architecture. Furthermore,  causal logic  may operate on one or more contexts and, equally important, a particular context might be shared between different causal logic thus enable efficient and salable context representation in complex dynamic systems. 
%
% Causaloid
%
\subsection{Causaloid}
\label{sec:epp_causaloid}

In the Effect Propagation Process, due to the detachment from a fixed spacetime, the fundamental temporal order is absent. Consequently, the entire classical concept of causality, where a cause must happen before its effect, can no longer be fundamentally established. The distinction between a definitive 'Cause' and a definitive 'Effect' becomes untenable as Russell foresaw. When the separation between cause and effect becomes untenable, then the obvious question arises: why even preserve an untenable separation?

Therefore, the Effect Propagation Process framework adopts the causaloid, a uniform entity proposed by Hardy\cite{HardyDynamicCausalStructure}, that merges the ‘cause' and 'effect' into a single entity. Instead of dealing with two nearly identical concepts discernible from each other by temporal order, the causaloid is a single entity that applies its "input" (cause), to a causal function that derives its "output" (effect), and whose relations to other causaloids define the causal structure and whose effect then propagates to the next causaloid. The nature of the causal function is not prescribed, allowing the Causaloid to encapsulate diverse logical forms, including but not imited to:

\begin{itemize}
	\item A deterministic rule (IF temp > 100).
 	\item A formal Structural Causal Model (SCM).
	\item A probabilistic estimate or Bayesian network.
	\item A specialized neural network.
\end{itemize}

For the deterministic case, the causal function takes some evidence as input, applies boolean operators (AND, OR) or comparators, and returns a boolean value as its PropagatingEffect. For a more complex causal scenario, the causal function encapsulates a set of structural causal equations,
applies the corresponding calculus and returns a probability distribution value as its PropagatingEffect.

In case of a probabilistic estimate or a Bayesian network, the causal function implements a Conditional Probability Table (CPT) or a similar probabilistic model, applies a probabilistic calculus i.e. the chain rule of probability, and returns another probability as its PropagatingEffect. If a Causaloid receives multiple PropagatingEffects, each carrying a probability, the receiving Causaloid implements the aggregation of all probabilities. This is a deliberate architectural principle rooted in the EPP's primary role as a flexible, hybrid framework. A specialized neural network embedded into a causal function will most likely return a classification score as its PropagatingEffect. In case the output of the neural network results in a complex type, for example 
generative data, then it is sensible to write its output into the appropriate context as a contextoid and return the context and contextoid ID as the PropagatingEffect. 


It is important to note that the EPP framework adopts the conceptual role of the Causaloid as a spacetime-agnostic unit of causal interaction, inspired by Hardy’s work on Quantum Gravity, but it does not uses Hardy's formal definition that requires a complex process matrix.  Instead, the EPP formulates the Causaloid as an abstract data structure that embeds a causal function, thereby decoupling it from any particular physical theory while preserving its core philosophical utility and making it practical implementable in software.

The term "propagation" refers to the fundamental process by which an effect is transferred within the structure from one Causaloid to another. This fundamental process is what gives rise to the appearance of propagation through spacetime in the classical view. Furthermore, while classical causality relies on a definite temporal order, the Effect Propagation Process treats temporal order as an emergent property, arising from the fundamental process itself.

While the Effect Propagation Process involves the transfer of effects within the fundamental structure, it is crucial to distinguish this from mere accidental correlation. The process reflects the fundamental way the underlying structure of reality establishes dependencies between its components and how it is gives rise to the non-accidental relationships we recognize as observed causal relations.This fundamental determination, rather than simple co-occurrence, is what the "Effect Propagation Process" captures at the deepest level.

 The Effect Propagation Process fundamentally inverts the notion of causal structure. Before the EPP, the causal structure was pre-supposed (i.e. DAG, a set of equations) in which variables, events, objects are placed. The consequence of this order is the fixed and often flat causal structure observed in classical methods of computational causality. The EPP, however, inverts the order and puts the causal entities first as monoidic primitives, and then introduces structure as relationships between these . The consequences is an innate fractal, self-referential definition of causal structure:

\begin{itemize}
	\item What is a causal structure? A set of relationships between Causaloids.
 	\item What is a causaloid? An entity that defines its relationships to other Causaloids. 
	\item What is a relationship? The pathway of propagating effects between Causaloids.
\end{itemize}

Therefore, a set of causaloids can represent arbitrary complex causal relationships because of this fractal, self-referential definition. It also follows from the definition that causality in the EPP has three primary modalities:
\begin{itemize}
	\item When the causal relations are fixed, the structure is static.
 	\item When the causal relations are changing, the structure is dynamic. 
 	\item When the causal relations are brought into being, the structure emerges. 
\end{itemize}

The core principle, that the entities define the structure and the structure is defied by its relationships between entities, holds true for all three modalities and, with it, establishes a principled foundation for dynamic. Because of its flexibility, the EPP can express static causal relationships similar to Pearl’s Causal DAG, it can handle probabilistic causal systems similar in spirit to Dynamic Bayesian Networks, but then goes further and  adds causal emergence and unifies both paradigms into one that is static and dynamic, deterministic and probabilistic while remaining structurally agnostic and thus allows for flexible geometric representation.

%
% Causaloid Collection
%
\subsection{Causaloid Collection}
\label{sec:epp_causaloid_collection}


Many real-world causal scenarios are not defined by a single cause but by the interplay of multiple factors. In practice, multiple modalities of causal aggregation may occur. For example, from a set of known causes, all of them must be true for an effect to occur. Then, in some cases, only one of many potential causes may lead to an effect. In other cases, more than one potential causes might be needed to trigger an effect, but not all known causes are required. To model these common collective structures , the EPP provides the Causaloid Collection.

A Causaloid Collection is a first-class entity that encapsulates a set of Causaloids and an explicit, configurable Aggregate Logic. This logic dictates how the individual PropagatingEffects of the member Causaloids are combined into a single, definitive outcome for the collection as a whole. This provides an ergonomic and principled way to express common causal patterns:

\begin{itemize}
\item \textbf{Conjunction (All):} The collection is active only if all of its member Causaloids are active.
\item \textbf{Disjunction (Any):} The collection is active if at least one of its member Causaloids is active.
\item \textbf{Absence (None):} The collection is active only if none of its member Causaloids are active.
\item \textbf{Threshold (Some(k)):} The collection is active only if at least a specific number, k, of its n member Causaloids are active.
\end{itemize}

In a conjunction, the causal collection is active only if all of its member Causaloids are active. For a disjunction, it is sufficient when just one cause of the causal collection is active. Negation inverts the conjunction in the sense that it's only true when all causes in a causal collection evaluate to false. For a threshold-based logic, the causal collection is active only when at least some K out of the collection of n causes are true. 

 The causal collection might seem to break from the EPP's geometric foundation, as the relationships between its members are not defined by explicit hyperedges. However,  the relationship of a Causaloid within a collection is not to its peers, but to the collection's aggregate logic itself. For example, a collection with All logic is the formal equivalent of a single hyperedge connecting all member Causaloids as a source set to a single target representing a logical AND gate. Disjunctive and other logics follow a similar principle, allowing for a simpler and more intuitive alternative to modeling these common use cases with a full hypergraph. By providing the causal collection, the EPP allows for the concise and efficient modeling of the most frequent types of causal structures.
 
  The Causaloid Collection proves particularly useful, for example, when modeling sensor fusion logic (k-of-n), multi-source object detection (All), or verifying safety interlocks (None). The verification of safety interlocks is a particular good example for causal collections because it allows for clear, verifiable, and auditable encoding of standard safety protocols commonly found in regulated industries such as robotics and avionics. For use cases that require nested or arbitrary complex causal relationships, the EPP provides the Causaloid Graph.


%
% Causaloid Graph
%
\subsection{Causaloid Graph}
\label{sec:epp_causaloid_graph}

Modeling real-world dynamic causal systems requires a mechanism capable of managing complexity.
Classical computational causality relies on algebra, which is rich in formalization,
but has its limits when complexity grows and thus limits scalability. The EPP adopts 
a geometric approach by expressing causal models as a hypergraph. The EPP
exchanges the arithmetic complexity of solving large equation systems for the challenge of managing structural complexity that comes from the geomtrization of causality.

In the EPP, the fractal, self-referential definition of causality directly translates 
to isomorphic recursive composition that enable concise expression of complex causal structures to manage structural complexity. A causal hypergraph may contain any number of nodes with any number of relations to other nodes, with each node representing a causaloid. A causaloid uniformly represents three distinct levels of abstraction:

\begin{itemize}
 	\item Singleton Causaloid: The base case, representing a single, indivisible causal mechanism.
 	\item A Collection of Causaloids: A set of Causaloids that can be evaluated with an aggregate logic. 
 	\item A Causaloid Graph: A node can encapsulate an entire graph
\end{itemize}

Recursive isomorphism allows to built causal models in a modular and hierarchical fashion. 
A complex sub-system can be modeled as a self-contained Causaloid Graph, then encapsulated into a single node to be used as a component in a larger, higher-level model. The causal graph enables the concise expression of deeply layered systems without sacrificing logical integrity.

The architecture of the Causaloid Graph is the direct physical manifestation of the EPP's core axioms. In accordance with the definition, the pathway of propagating effects, the relationship between Causaloids, is the hyperedge that connects the causaloid nodes. The Effect Propagation Process is the operational dynamic on this graph. When triggered, Causaloids are evaluated. Their outcomes, the PropagatingEffects, propagate along these hyperedges to other Causaloids, which in turn evaluate their own functions, thus continuing the process until the graph traversal completes and a final, reasoned inference is reached.

%
% PropagatingEffect
%
\subsection{PropagatingEffect}
\label{sec:propagating_effect}

The EPP emphasizes uniformity and, just like the causaloid folds cause and effect into one uniform unit, the PropagatingEffect folds causal input and output into one uniform unit. Its purpose is to distill the result of the node's reasoning into a clear, actionable directive that is passed to the next causaloid as its input. The PropagatingEffect represents a unified inference outcome across different reasoning modalities. By design, the EPP supports the following reasoning modalities:

\begin{itemize}	
	\item Deterministic
	\item Probabilistic 
	\item Mixed, deterministic and probabilistic 
\end{itemize}

The deterministic mode facilitate logical reasoning using boolean logic. A state is either true or false. The EPP recognizes that, while there is a clear use case for deterministic causal reasoning, there is also an equally important use case for probabilistic causal reasoning. Also, the EPP only provides the reasoning mechanism, but leaves the exact details of the reasoning mechanism as implementation details of the causaloid. The wisdom of this decision comes from the realization that the EPP may be used in different scenarios with different requirements and therefore it leaves the exact reasoning details to the practitioner. One important detail on the mixed reasoning. While it is designed internally to convert all boolean state to probabilities and as then reasons only over  probabilities, its final outcome is actually a deterministic boolean relative to a probabilistic threshold. In the DeepCausality implementation, all reasoning modes are traits with a default implementation thus leaving the practitioner the option to overwrite the default mode with a custom implementation when the need arises. Because the mixed modalities require different input and output types, the PropagatingEffect is isomorphic recursive to represent a variety of different reasoning types such as:

\begin{itemize}	
	\item Primitive Types: Deterministic, Numerical, and Probability values
	\item Complex Structures: Map or Graph for passing complex, structured, or relational data between causaloids.
	\item Contextual Link: A reference to a specific fact in the context to find the PropagatingEffect . 
	\item None: Explicitly represent no effect.
	\item Referral: A type that contains a PropagatingEffect and reference to another causaloid to process it.
\end{itemize}

The Contextual Link accommodates for advanced causal reasoning via non-numerical representations by writing a complex reasoning outcome directly into the context and then propagating the reference to the next reasoning stage which reads the complex reasoning outcome and processes it further. For example, the Symbolic context type combined with the Contextual Link establishes a foundation for a uniform integration of multi-modal causal reasoning with advanced neuro-symbolic reasoning.

  
The EPP then uses the propagating Effect to enables several distinct modes of causal reasoning. In a causal graph, the EPP enables complex reasoning in one of three ways: 

\begin{itemize}	
	\item \textbf{Static Reasoning}
	\item \textbf{Dynamic Reasoning}
	\item \textbf{Adaptive Reasoning} 
\end{itemize}


\textbf{Static Reasoning:} 

The entire causal graph is traversed according to its pre-defined structure. The reasoning is static because the reasoning path is always fixed. 

\textbf{Dynamic Reasoning:} 

A sub-graph or a specific path (such as the shortest path) is evaluated, allowing for targeted, context-dependent reasoning within the larger graph. It is dynamic reasoning because the pathway through the graph is determines at runtime via one of the EPP methods for graph traversal. 

\textbf{Adaptive Reasoning:} 

The Causaloid itself determines the next step in the reasoning process conditional on its reasoning outcome. Based on its own internal logic, a Causaloid can dynamically dispatch the flow of causality to another Causaloid in the graph, enabling adaptive reasoning. To illustrate conditional reasoning, a clinical patent risk model may operate very differently for patients with normal blood pressure compared to high blood pressure patients. Therefore, two highly specialized models are defined and a dedicated dispatch causaloid queries its context for the latest blood pressure measurements and its recent history, uses its internal logic to decided the level of blood pressure and then dispatches all further reasoning to the specialized causal model for the detected blood pressure level. Adaptive Reasoning can be combined with either a static or dynamic causal graph. In a static graph, all potential reasoning pathways must be defined upfront. In a dynamic causal graph, new causaloids might be added dynamically i.e. in response to a changing context and then the dispatch causaloid gets replaced with a new one that can dispatch to the newly created reasoning causaloids to enable dynamic adaptive reasoning.  

%
% Causal State Machine
%
\subsection{Causal State Machine}
\label{sec:epp_csm}

The causaloid and causal graph provides the mechanism for causal inference, 
but they lack the ability of intervention. The EPP addresses this through the Causal State Machine (CSM), which serves as the formal bridge between causal reasoning and deterministic intervention.

The CSM originates in Finite State Machine (FSM) in that it aims to formalize state transition.
However, a defining property of the Finite State Machine is its explicit 'Finiteness': the entire set of possible system states must be known at design time. The FSM paradigm is highly effective for closed-world problems where all conditions are predictable and known. However, the finiteness of states becomes untenable when applied to dynamic causality. The Causal State Machine generalizes the FSM and adapts it 
to operationlize interventions for dynamic causality through two mechanism:
 
\begin{itemize}
	\item A "Causal State" is an Inferred Predicate. 
	\item The "Causal Action" is a Deterministic Intervention based on the  Causal State.
\end{itemize}

In a classical FSM, a state is an identifier from a pre-defined list (e.g., "State A").
In the CSM, a Causal State is a inferential predicate defined as a specific Causaloid whose truthfulness is evaluated. The CSM does not need to know all possible states in advance. It only requires the causal logic (the Causaloids) necessary to infer whether the encoded predicate in the "Causal State" is true. 

Each Causal State is formally linked to a Causal Action. This is a deterministic, programmatic function that is executed if and only if its corresponding Causal State is inferred to be true. This action represents a real-world intervention.

The CSM is a inference-to-action state machine that is both deterministic in its execution and dynamic in its definition. The CSM is deterministic within its encoded caudal states and actions, but also dynamic in its definition as it can be extended at run-time by adding new Causal States and Actions, enabling the control logic of a system to evolve in tandem with the causal understanding of its environment. 

%
% Mapping Pearl's Ladder of Causation 
%
\subsection{Mapping Pearl's Ladder of Causation to the EPP}
\label{sec:epp_ladder_causation}

Judea Pearl's Ladder of Causation\cite{pearl2000causality} defines three distinct levels of ability required for causal reasoning: Association, Intervention, and Counterfactuals. The EPP achieves these three rungs of the ladder by different means than the established methods of the SCM and Causal DAG.  

\textbf{Rung 1: Association}

The first rung, Association, concerns reasoning from observational data. 
It answers the question, "What is the likelihood of Y, given that we have observed X?" In classical models, this is handled by conditional probabilities i.e $P(Y|X)$.

In the EPP, association is a structured, operational process:

\begin{enumerate}
	\item The observation $(X)$ is formalized as Evidence and presented as an input to a Causaloid.
	\item The background condition $(|)$ is represented by the context, which provides the necessary supporting data for the reasoning process.
	\item The causal inference of $(Y)$ is performed by the causal function embedded within each Causaloid. This function takes the Evidence and any required information from the Context as its inputs and computes a result.
	\item The inference result is emitted as a PropagatingEffect, which then travels along the graph's hyperedges, serving as Evidence for subsequent Causaloids.
\end{enumerate}

Thus, "seeing" in the EPP is the operational dynamic where initial Evidence triggers a cascade of computations via the causal functions throughout the Causaloid Graph, leading to a final, reasoned inference.

\textbf{Rung 2: Intervention}

The second rung, Intervention, involves predicting the effects of deliberate actions. It answers the question, "What would Y be if we do X?" This is formalized in Pearl's framework by the do-operator, which simulates an intervention on the causal model itself.

The EPP provides a mechanism of intervention through the Causal State Machine (CSM). 
The CSM  links causal inferences to deterministic actions:

\begin{itemize}
	\item A Causal State is defined as an inferential predicate. It is a specific Causaloid evaluated against a specific Context.
	\item This Causal State is mapped to a Causal Action, a verifiable function that executes when its corresponding state is inferred to be true.

\end{itemize}

This Causal Action is the EPP's intervention. It is a programmatic function that changes state. 
This change is then reflected as an update to the context, creating a complete feedback loop of inference, action, and new observation.

\textbf{Rung 3: Counterfactuals}

The third rung, Counterfactuals, involves reasoning about alternative possibilities given a known outcome. It answers the retrospective question, "What would Y have been if X had been different, given that we actually observed Z?"

The EPP's architecture provides a Contextual Counterfactual mechanism, which leverages the EPP's externalization of context:

\begin{enumerate}
	\item Abduction is Context Pinning
	\item Action is Contextual Alternation
	\item Prediction is Re-evaluation over an altered context. 
\end{enumerate}

The factual observation $(Z)$ is already explicitly represented within the primary context. 
The abduction step is therefore equivalent to identifying and "pinning" this factual context.

The hypothetical premise ("if X had been different") is then established by creating a new, hypothetical context $(C_counterfactual)$ by cloning the primary context $C_factual$ and modifying the value of the relevant Contextoid.The system then executes the exact same, unmodified Causaloid Graph, but uses $C_counterfactual$ as its frame of reference. The resulting inference is the answer to the counterfactual query. 


The EPP's mechanisms of causation differ from Structural Causal Models, 
but they fulfill the same fundamental goals of 'seeing,' 'doing,' and 'imagining' Judea Pearl established
via the ladder of causation. Table \ref{tab:ladder_comparison} summarizes the comparison of the EPP to the existing methods of computational causality.
 

\begin{table}[h!]
\centering
\caption{Comparison of Causal Ladder Implementations}
\label{tab:ladder_comparison}
\begin{tabular}{|l|p{5.5cm}|p{5.5cm}|}
\hline
\textbf{Ladder Rung} & \textbf{Pearl's Framework (SCM/DAG)} & \textbf{Effect Propagation Process (EPP)} \\
\hline
\textbf{1. Association} &
Statistical analysis; calculating conditional probability $P(Y|X)$. &
Execution of a \texttt{causal function} on \texttt{Evidence} within a factual \texttt{Context} ($C_{\text{factual}}$). \\
\hline
\textbf{2. Intervention} &
The \textit{do}-operator; surgical modification of the model's structural equations. &
Execution of a \texttt{Causal Action} by the \texttt{Causal State Machine (CSM)} in response to an inferred state. \\
\hline
\textbf{3. Counterfactuals} &
Three-step algorithm: Abduction (solving for latent variables), Action (model surgery), and Prediction. &
Three-step process: Context Pinning, Contextual Alternation, and Re-evaluation of the \textit{unmodified model} over an \textit{altered context} ($C_{\text{counterfactual}}$). \\
\hline
\end{tabular}
\end{table}

The decision to separate causal logic (the Causaloid Graph) from its data (the Context) that underpins
contextual alternation leads to some welcome properties. For example, through contextual alternation,  counter-factual reasoning becomes an "embarrassingly parallel" problem because, if 100 alternate contexts are derived, all of them are independent from each other and thus can be evaluated in parallel. 


%
% Mapping Dynamic Bayesian Networks
%
\subsection{Mapping Dynamic Bayesian Networks to the EPP}
\label{sec:epp_Dynamic_Bayesian_Networks}

Dynamic Bayesian Network is the established framework for modeling dynamic causal systems. A DBN models a temporal process by "unrolling" a causal graph over discrete time slices, creating separate nodes for a variable at each point in time. The EPP represents this same process   by evaluating a single, static causal model over a dynamic, temporal context hypergraph. The mapping of DBN to EPP components constructs as following:
 
 \textbf{Time Modeling:}
 
 In a DBN, time is an implicit index of the temporal variables. In the EPP, time is made explicit within a
 context by representing each time slice (e.g., $X_{t-1}$, $X_t$, $X_{t+1}$) as a Tempoid, a temporal type of Contextoid, with their sequential relationship defined by hyper-edges within the context hypergraph. In the EPP data might be attached to a Tempoid as a dedicted node of a different type i.e. Datoid. 

 \textbf{State Variables:}
 
state variable in a DBN (e.g., the concept of Weather across time) corresponds to a single Causaloid in the Causaloid Graph. The Causaloid represents the variable's underlying causal mechanism and the state of "Weather at time t" is the result of evaluating the "Weather" Causaloid contextual using the Tempoid that maps to the time t. A contextual temporal graph allows a Causaloid to access uniformly multiple slices of time at different scales i.e. weekly average rainfall and today's rainfall to inform its causal logic. 

\textbf{Dependencies:}

The directed edges in a DBN can reference  within the same time slice or across different time slice.
For edges within the same time slice, (e.g., $\text{Weather}_t \to \text{Umbrella}_t$), the causal function simply references its causal logic to the one tempoid at time t in the graph. If "Weather" is a complex state object, then the causaloid may loads it from another context before evaluating the causal rule that would lead to Umbrella become true.

For edges between different time slices (e.g., $\text{Weather}_{t-1} \to \text{Weather}_t$),  are represented by the hyperedges in the Causaloid Graph by referencing two different Tempoid nodes. Practically, one would implement a dynamic temporal graph index with accessors for frequently used "current" or "previous" values. 


\textbf{Conditional Probability Tables (CPT):}

Conditional Probability Tables (CPTs): The CPT defining a variable's probability given its parents
(e.g., $P(X_t \mid Z_t, X_{t-1})$) is implemented as the causal function within the Causaloid.


\textbf{Execution Flow:}

To compute the state of the system at time t, the causal function of a Causaloid queries the Context to determine the current time slice. It receives the PropagatingEffects from its parent Causaloids (representing their states at the appropriate time slices) and uses its internal CPT logic to compute a new probability distribution. This distribution is then emitted as a new probabilistic PropagatingEffect. This process maps the EPP to the "filtering" or "unrolling" inference of a DBN.
%
% Mapping Granger Causality
%
\subsection{Mapping Granger Causality to the EPP}
\label{sec:epp_Granger_Causality}

Granger causality is a foundational concept for causal inference in time-series data, particularly in econometrics. It is used to solve practical problems, for instance, determining if past changes in the price of oil can be said to "Granger-cause" future changes in shipping industry activity. 
A time series $X(oil price)$ is said to "Granger-cause" another time $Y(shipping activity)$ series if the past values of  $X$ contain information that helps predict the future values of $Y$ 
 better than using the past values of $Y$ alone. It is fundamentally a test of predictive utility. The EPP's architecture, with its first-class treatment of time and context, provides a natural and powerful framework for modeling this scenario:

\begin{itemize}
	\item \textbf{Time-Series as a Temporal Context:} The historical data for both oil prices and shipping activity are represented within the EPP context. This is modeled as a sequence of Tempoid nodes (representing months or quarters), each linked to Datoid nodes containing the respective values for $X(oil price)$ and $Y(shipping activity)$ at time t.

	\item \textbf{The Predictive Model as a Causaloid:} The predictive model for shipping activity is encapsulated within a dedicated `Causaloid`. This Causaloid's purpose is to predict the next value of shipping activity, $Y_{t+1}$, by querying the `Context` for past values.

	\item \textbf{The Granger Test as a Counterfactual Query:} The core question of "Do past oil prices improve the prediction of future shipping activity?" is a fundamentally counterfactual query. The EPP models this directly using its Contextual Alternation mechanism:
    \begin{enumerate}
        \item A "Granger Test" Causaloid initiates two parallel, hypothetical evaluations.
        \item In the first evaluation, the Causaloid is allowed to query the complete, factual `Context`, which contains the history of both oil prices and past shipping activity.
        \item In the second evaluation, the Causaloid is evaluated against a hypothetical, alternate `Context`, $C'$, where the history of oil prices is deliberately excluded or masked.
        \item The "Granger Test" Causaloid then compares the prediction error from both evaluations. If the error is significantly lower in the evaluation that included the history of oil prices, the test concludes that oil price Granger-causes shipping activity.
    \end{enumerate}

\end{itemize}

The EPP's temporal Context is not restricted to linear time steps; it can be a rich hypergraph representing multiple time scales (e.g., daily price volatility and quarterly shipping trends). Furthermore, the Causaloid is not restricted to the linear models typical in econometrics. This allows for the construction of more sophisticated, non-linear, and multi-scale versions of Granger-causal tests

%
% Mapping Rubin Causal Model
%
\subsection{Mapping Rubin Causal Model (RCM) to the EPP}
\label{sec:epp_rubin_causal_model}

The Rubin Causal Model (RCM), also known as the Potential Outcomes framework, is a cornerstone of modern causal inference, particularly in statistics, econometrics, and the social sciences. The RCM defines the causal effect on a specific unit, $i$, as the difference between two potential outcomes: $Y_{i}(1)$, the outcome if the unit receives the treatment, and $Y_{i}(0)$,  the outcome if the unit does not eceives the treatment. The central challenge of the RCM, termed the "fundamental problem of causal inference," is that for any given unit, only one of these two potential outcomes can ever be factually observed.  

The EPP models the scenario of potential outcomes as contextual alternations. From a base context, say $C_i$, two alternate contexts are derived, one $C_i'$  with the treatment applied and another one,  $C_i''$ with the control applied. From there, the two potential outcomes for unit $i$ are therefore defined as:

\begin{itemize}
	\item  $Y_i(1)$ is the final `PropagatingEffect` that results from evaluating the system's `CausaloidGraph` against a context, $C_i'$ where the treatment has been applied.
	\item $Y_i(0)$ is the final `PropagatingEffect` that results from evaluating the exact same `CausaloidGraph` against another hypothetical context, $C_i''$ where the control has been applied.
	\item Estimate the difference between the PropagatingEffect resulting from $Y_i(1)$  and the PropagatingEffect resulting $Y_i(0)$ as the causal effect on a unit $i$. 
\end{itemize}

From the EPP's perspective, the "fundamental problem of causal inference" is physical constraint that only applies to physical measurements. The EPP, as a computational framework, treats counterfactuals via its contextual alternation mechanism. The EPP can instantiate and evaluate the causal outcomes for both the treatment and control contexts in parallel thus estimate the difference between two potential outcomes. This mapping demonstrates that the RCM's core concepts are a natural fit within the EPP's architecture and the EPP provides a mechanism to extend the RCM with a richer, dynamic, and non-Euclidean context.

%
% Mapping Conditional Average Treatment Effects (CATE)
%
\subsection{Mapping Conditional Average Treatment Effects (CATE) Inference to the EPP}
\label{sec:epp_cate}

The estimation of Conditional Average Treatment Effects (CATE) is a critical goal of modern applied causal inference, particularly in domains like personalized medicine. CATE is defined as the expected causal effect of an intervention for a specific individual or sub-population, conditioned on their unique characteristics. The purpose of CATE is to move beyond population averages and determine for whom a treatment is beneficial, harmful, or ineffective.

It achieves this by leveraging the Rubin Causal Model (RCM). CATE is formally expressed as $\tau(x) = E[Y(1) - Y(0) | X=x]$, where $Y(1)$ and $Y(0)$ are the potential outcomes. While the definition is elegant, applying it to real-world observational data is a challenge, as only one potential outcome is ever observed. This challenge necessitates a two-stage process:
\begin{itemize}
	\item Stage 1 (Discovery): Data science discovers and validates causal links.
	\item Stage 2 (Inference): The causal links are operationalized to answer specific CATE queries. 
\end{itemize} 

It is crucial to position the Effect Propagation Process correctly within the broader landscape of computational causality. The EPP is a foundational framework for causal reasoning, simulation, and operations. In its current form, it is not a tool for automated causal discovery from raw observational data. For contextual causal learning within the EPP, more work will be necessary. Therefore, all existing methods of causal discovery methods remain indispensable for inferring causal graphs from observational data. In an EPP-based workflow, these tools are invaluable for building and validating the initial causal graph. A function learned via a tool like DoWhy or EconML can be directly encapsulated within a Causaloid. The following mapping of CATE inference presumes a causal graph has been found and validated with existing methods and thus is scoped to operationalize the inference stage of CATE. The inference state of CATE maps to the EPP in two different modalities: Static and Dynamic.


\subsubsection*{Representing Static CATE in the EPP}

The EPP models a static CATE query as a formal, computable, counterfactual simulation. This is achieved by mapping the core concepts of the query onto the EPP's architectural primitives:

\begin{itemize}
\item \textbf{The Condition $X=x$ as a Static Context:}
The unit's complete set of pre-treatment covariates, $X=x$, is represented by a static \texttt{Context} ($C_x$). This context serves as the factual "ground truth" for the unit's state at the moment of the query.

\item \textbf{The Learned Function as a `Causaloid`:}
The causal relationships and the CATE function (`$\tau(x)$`) that were discovered in Stage 1 (e.g., using DoWhy) are encapsulated within the causal logic of one or more \texttt{Causaloids}. For a simple case, a single `CATEstimator` \texttt{Causaloid} might contain the entire learned function. In a more complex model, this might be a full \texttt{CausaloidGraph} representing the mechanistic pathways of the treatment.

\item \textbf{Potential Outcomes via `Contextual Alternation`:}
The EPP computes the potential outcomes, `$Y(1)$` and `$Y(0)$`, not through statistical adjustment, but through direct, parallel simulation. This is achieved via the EPP's core counterfactual mechanism:
\begin{enumerate}
    \item \textbf{Abduction:} The factual, pre-treatment state of the unit is established by "pinning" the static context, `$C_x$`.
    \item \textbf{Action:} The system then creates two hypothetical, parallel realities by cloning this base context:
        \begin{itemize}
            \item A `treatment` context (`$C_1$`) is created where the treatment is applied (e.g., by introducing specific \texttt{Evidence} to a "treatment" \texttt{Causaloid}).
            \item A `control` context (`$C_0$`) is created where the control is applied.
        \end{itemize}
    \item \textbf{Prediction:} The EPP evaluates the entire, unmodified \texttt{CausaloidGraph} twice—once against the treatment context `$C_1$` to compute `$Y(1)$`, and once against the control context `$C_0$` to compute `$Y(0)$`.
\end{enumerate}

\item \textbf{The CATE as the Final `PropagatingEffect`:}
The final CATE value, `$\tau(x)$`, is the directly computed difference between the two `PropagatingEffects` representing the potential outcomes. The entire workflow can be encapsulated in a single `CATECausaloid` that orchestrates this simulation and returns the final estimate.
\end{itemize}


\subsubsection*{Representing Dynamic CATE in the EPP}

In practice, complex systems evolve over time. Taking a patient's hospital stay as an example, diagnostic establishes a ground truth, treatment is administered, and depending on the effectiveness of the treatment, further treatment may follow until the patient's health has improved up to the stage at which a discharge is warranted. Medical professionals experience this reality every day but classical CATE struggles to capture the temporal progression because it can only provides a single estimate for a frozen moment in time, a property inherited from the underlying RCM methodology.   

The EPP, by contrast, provides a complete architecture for Dynamic CATE that captures temporal causal progression by leveraging the existing EPP primitives:

\begin{itemize}
\item \textbf{Dynamic CATE ($\tau(x, t)$) via Evolving Contexts:}
A patient's state is not static; it evolves. In the EPP, this is modeled by a dynamic \texttt{Context} that is updated with new clinical data over time. The EPP can therefore compute the CATE not just once, but continuously as the patient's \texttt{Context} changes. The result is a dynamic CATE estimate, $\tau(x, t)$, that provides a longitudinal, real-time view of treatment efficacy, allowing for intervention strategies that are continuously adapted to a patient's changing condition.

\item \textbf{Context-Aware Model Selection:}
The most profound challenge in long-term treatment is that the patient's underlying causal mechanisms can change. For example, a patient may develop a known pathway for drug resistance. The EPP can handles this not with unpredictable emergence, but with verifiable, dynamic model switching. A clinical EPP model can contain a library of multiple, pre-built, and independently validated causal sub-models (e.g., `SubGraph\_NormalResponse`, `SubGraph\_ResistancePathwayA`). A high-level `TriageCausaloid` continuously monitors the patient's evolving `Context`. If it detects a specific biomarker that indicates the onset of drug resistance, it uses the EPP's Dynamic Dispatch (`RelayTo`) mechanism to seamlessly and deterministically route all future reasoning through the appropriate `SubGraph\_ResistancePathwayA`. 

This provides the full benefit of an adaptive system by responding correctly to a fundamental change in the patient's state while remaining fully deterministic, auditable, and verifiable, as the set of all possible causal models is fixed and validated at design time. Also, in case the TriageCausaloid encounters an undecidable situation, it can trigger a predefined and validated safety protocol to inform medical experts of the detected anomaly and provide the full proceeding context. 

\item \textbf{Certified Assurance:}
In a dynamic system, safety is paramount. The EPP integrates estimation with control at an architectural level. Any treatment recommendation, whether from a single model or as the result of a dynamic switch between models, is merely a proposal. The \texttt{Causal State Machine (CSM)} provides an architectural guarantee that this proposal will be deterministically verified against a \texttt{Certified Assurance Enclave} of immutable clinical safety rules (e.g., dose limits, contraindications, FDA rules) before any action is proposed to ensures the entire system remains verifiably safe at all times.

\end{itemize}


The EPP at this stage may have not causal structural learning, but it offers a different set of properties that makes it well suited to implement dynamical causality in domains that require dynamic adaptation, context aware model selection, and verifiable safety. By converting existing static CATE model to the EPP, first hand experience can be gained which then informs the exploration of gradual introduction of dynamic causality and thus offers a scalable pathway forward.  


\subsection{Discussion}
\label{sec:epp_discussion}

The preceding sections have laid out the architectural components of the Effect Propagation Process. However, the capacity of the EPP to model dynamic systems where the causal structure itself can evolve introduces a class of challenges that reach beyond the scope of formalism alone. To ensure that the EPP is built upon a sound, coherent, and trustworthy foundation, it is required to first understand the inherent higher-order consequences of its dynamic design from first principles.

Therefore, the subsequent philosophical chapters establish the first principles of the EPP. The Metaphysics in section \ref{sec:metaphysics} will establish the EPP's first principles of being and change. The Epistemology in section \ref{sec:epp_epistemology} will explore the far-reaching consequences for knowledge and truth in such a system. Finally, the Ontology in secction \ref{sec:epp_ontology} will use these insights to structure a safe and sound set of primitives that are ready for rigorous formalization in section \ref{sec:formalization} and implementation in section \ref{sec:implementation}. 

\newpage
