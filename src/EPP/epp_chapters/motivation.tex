\section{Motivation}
\label{sec:motivation}

In his seminal 1985 essay, "Programming as Theory Building," \cite{naur1985programming}, Turing Award winner Peter Naur argued that the act of creating a significant software system is not one of mere coding, but of building a deep, explanatory theory. The source code is just a formal notation; the real program is the mental model of how it works and, more importantly, why it was built that way. 
This monograph is a deliberate attempt to use programming and theory building as a joint force to 
apply the Naur principle synergistically where the implementation imposes new challenges on the theory 
and the theory guides a stronger, more principled implementation. 


The pre-existing philosophy of causality served mankind for millennia, and one might be tempted to conclude that this is all there is to know about cause and effect. However, the origin of the Effect Propagation Process (EPP) did not start in philosophy, but in three distinct problems. The first problem is related to non-Euclidean data representation, the second problem is rooted in causal inference over non-linear time representations, and the third in handling dynamic causal structures.

\subsection{Non-Euclidean representation}

The first problem applies equally to computational causality and deep learning; therefore, it is best illustrated with familiar  large language models. Language embeddings remain foundational to contemporary large language models (LLMs), but these require a reduction into a vector space because many prevalent LLM architectures operate efficiently in vector spaces, thus making the reduction from non-Euclidean realms (language) into a Euclidean representation (Vector space) mandatory. Instead of advancing LLM architectures to natively handle non-Euclidean representations, the industry has focused on leveraging Vector databases for storing and retrieving embeddings derived from LLMs. Graph neural networks operate on non-Euclidean spaces, but as these are not yet commonly adopted as core components in mainstream LLM architectures, the problem prevails.

\subsection{Non-linear Time}

However, when generalizing space beyond Euclidean, then the second problem emerges: how to represent time? More profoundly, can we separate time and space from data? Out of this insight, the idea emerged to separate space, time, and data into a separate context usable by multiple models. As space and time were elevated from an implicit background into an explicit first-class context representation, moving beyond correlation towards causality became the next obvious step. At this moment, a profound problem emerged: When space is non-Euclidean, and time might not be a simple linear progression, then how do we establish a causal relationship?
As it turned out, establishing a clear causal relationship became problematic within the classical definition of causality, which fundamentally relies on a linear time-asymmetric ordering (cause preceding effect) within its assumed background spacetime.

One might challenge the presumption of non-linear time progression, but in complex systems with dynamic feedback loops, it is perfectly possible to see context structures that entail non-linear time regions. Non-linear time regions can occur when the background time is represented as a temporal hypergraph that holds multiple time resolutions simultaneously. The simultaneous presence of time units at different scales breaks the simple time-linear assumption (all time has the same unit, and therefore moves at the same rate) that computational causality tools commonly make.

Furthermore, in a temporal hypergraph, the unit of time is scale-dependent, which means in order to compare temporal values, one must consider the scale to make a valid comparison between equally scaled values (hour X compared to hour Y). Less obvious, a temporal hypergraph, by design, holds all past and present temporal values simultaneously within its structure. This co-existence of multiple temporal points simplifies non-trivial temporal arithmetic over hetero-scaled time units, yet it imposes a vexing problem: How do you know if a time value in a node of the graph is current or past?

The problem is non-trivial because, as time progresses, the engulfing context engine continually generates the non-Euclidean temporal hypergraph representation with the implication that, at one lookup, the value of a temporal node is current, but at the next one, it might be past; however, the exact temporal distance at which a “present” value becomes “past” depends on the node's time scale. A node holding a temporal value “hour” will be valid for 60 minutes; that means a lookup every ten minutes will yield the current hour 6 times, but handling the seventh lookup leads to a fundamental design decision that illustrates the implied complexity.

A “dynamic-position” design means, when a new hour starts, a new node will be added; therefore, the seventh lookup returns a past value. By implication, the index of the new node needs to be looked up to retrieve the value of the new current hour. Therefore, a “dynamic-position” design requires a dynamic index to locate current values.

A “static-position” design means, when a new hour starts, the previous current value will be overwritten with the understanding that the seventh lookup returns the new current value. By implication, the index of the current value always remains static. Therefore, a “static-position” design requires a fixed index, i.e., a lookup table to locate current values. Use cases exist for both scenarios and in practice, temporal hypergraphs use a mixture of static and dynamic positioning to handle different types of relative values, e.g., current day, last year, next hour, and similar.

Exacerbating the problem further, feedback loops across different time scales using different relative values may dynamically modify the temporal hypergraph itself to capture non-regular observations or to add estimations at future time values that have not yet occurred.   
At this point, it becomes abundantly clear that the assumption of a simple, unidirectional linear temporal order required for establishing cause-and-effect becomes untenable.

At the same time, causal relations remain valid in those non-linear regions. Additionally, the designation of a cause purely based on strict temporal order feels arbitrary in a temporal hypergraph in which past, present, and estimated future temporal values across multiple time scales all exist simultaneously. Regardless of static or dynamic location of relative values, the definition of causality had to evolve to match the reality of modeling causal structures across complex multimodal hypergraphs.


\subsection{No a-priori causal structures}

When modeling dynamic feedback loops across different time scales, the third problem emerges eventually: Not all causal structures are known upfront. There are cases where the causal structure emerges from the prevalent context predominantly in response to a change in externalities. For example, in the financial industry, a shifting volume imbalance indicates an emerging regime change. The exact cause for the shifting volume imbalance can be attributed to externalities such as breaking news. However, in the absence of internal references, the subsequent  causal structure emerges as part of the unfolding regime change. There is no possible way to know the new structure upfront therefore, it cannot reliably be modeled ahead of time. Likewise, in correlation-based methods, a similar phenomenon unfolds because, in the absence of internal references, the deep learning model cannot predict correctly anymore because data during an emerging regime change falls outside its training data distribution. The mechanism is different, but the outcome is the same: that previously reliable models crater in novel situations.

The previously identified limitation of temporal order directly applies to dynamic regime changes because, if the new causal structure has not yet emerged, how can we know its temporal structure beforehand? In short, we cannot know reliably anything about emerging causality up to the moment it emerges.

These three problems, non-Euclidean representation, non-linear temporal structures, and emerging causality deeply interrelate with each other and thus defy overly simplistic solutions. For example, advanced graph neural networks work on non-Euclidean data representation, but fail on non-linear temporal structures. One might be tempted to build non-linear-time graph neural networks, but this does not address the problem of non-Euclidean data representation and emerging causality. There is research to combine methods from computational causality with deep learning, but these approaches are focused on non-Euclidean representation without integrating the challenges of non-linear temporality and emergent causal logic.

\subsection{Boundaries of Classical Causal Models}

The established methods of computational causality, particularly the frameworks developed by Pearl, Granger, and Rubin, represent monumental intellectual achievements that form the foundation of the field. The purpose of the following analysis is to carefully delineate the set of assumptions, such as a fixed spacetime and a static causal structure, upon which they were designed to operate. By clearly defining these boundaries, we can identify the emerging class of problems in modern dynamic systems that now fall outside this classical scope. 


\subsubsection*{Granger Causality}

Granger Causality \cite{granger1969causal} is used for time-series data where past values of one time-series are used to predict values of another time series. In a strict sense, Granger Causality tests if one variable (say X) predicts another variable (Y) through a series of t-tests and F-tests on lagged values of variable X.

\textbf{Assumptions:}

Granger causality assumes a stable causal structure and a linear, uniform time representation with consistent intervals.

\newpage

\textbf{Implications:}

\begin{itemize}
    \item \textbf{Non-Linear Time:} Granger causality cannot handle non-linear time representations.
    \item \textbf{Non-Euclidean Representation:} Granger causality operates on time-series values within a Euclidean representation. It cannot be applied to a non-Euclidean representation.
    \item \textbf{Emergent Causality:} Because of the assumption of a stable causal structure, Granger causality cannot operate on emergent causal structures.
\end{itemize}


\subsubsection*{Pearl's Causal DAGs and Structural Causal Models (SCMs)}

Judea Pearl pioneered the formalization of causality that underpins the majority of contemporary methods of computational causality. The framework of Structural Causal Models \cite{pearl2000causality} (SCMs) rests upon the assumptions of Directed Acyclic Graphs (DAGs).

\textbf{Assumptions:}

Pearl's causal framework is exceptionally powerful for reasoning about interventions given a known or discovered causal model.
The framework assumes: 

\begin{itemize}
    \item Acyclicity (DAG): Causal relationships are acyclical in a directed acyclic graph.
    \item Static Causal Structure: The causal graph, once defined, is assumed to be static.
    \item Fixed background spacetime: Variables in the DAG are assumed to be embedded within a fixed background spacetime.
\end{itemize}


\textbf{Implications:}

\begin{itemize}
    \item \textbf{Non-Linear Time:} The acyclical assumption explicitly prohibits feedback loops, and the fixed background spacetime assumption prevents any form of non-linear time.
    \item \textbf{Non-Euclidean Representation:} The DAG structure could potentially allow for non-Euclidean representation, but existing tooling assumes Euclidean structures and thus does not allow non-Euclidean representation.
    \item \textbf{Emergent Causality:} The assumption of static causal structure prevents any handling of causal emergence.
\end{itemize}

The analysis of classical models reveals a consistent set of boundaries, built upon assumptions of a fixed, linear spacetime and a static causal structure. While these assumptions enable powerful reasoning within their defined domains, they become untenable when confronted with a class of problems of increasing importance in safety-critical and complex systems. 

\subsection{Beyond Classical Causal Models}

The need for the Effect Propagation Process arises directly from modeling complex dynamic systems, which are characterized by three deeply interrelated challenges: non-Euclidean representation, non-linear temporality, and dynamic causal emergence. The most critical challenge is dynamic causal emergence, where the causal laws of a system are themselves subject to change. This is  a practical reality in numerous domains. In financial markets, for instance, the causal relationships between assets are relatively stable during normal conditions but undergo a fundamental "regime shift" following a black swan event or a major policy change. The old causal graph becomes obsolete, and a new one emerges in response to the new market dynamics.

In contemporary plasma fusion, it is well understood that the magnetic confinement field and the turbulent plasma it contains exist in a tightly\-coupled feedback loop, where each dynamically influences the other in real-time. In such systems, the very nature of the causal relationships can change depending on the energy scale, a phenomenon known as "dynamic phase alignment", rendering classical acyclic or linear-temporal causal models insufficient\cite{Milanese_2021}.

Similarly, in climate science, ecological systems can cross "tipping points" where gradual changes trigger new, powerful feedback loops, fundamentally altering the causal structure of the climate model. This dynamic nature exacerbates the problem of non-linear time. In a system with emergent feedback loops, such as in climate modeling or high-frequency trading, the notion of a single, uniform temporal progression becomes untenable. Events on nanosecond, daily, and quarterly scales can all interact, forming a complex temporal hypergraph where causal influence is no longer a simple unidirectional arrow. 

Complex causal relations are often expressed through non-Euclidean representations. 
For example, a medical record documenting a patient's health cannot be reduced to a simple vector of measurements. 
It is a complex graph of relationships between genomic data, electronic health records, comorbidities, and environmental factors. 
Likewise, a global supply chain is not a rigid grid but a dynamic network of dependencies. Reducing these relational structures to a Euclidean vector space to fit classical models often destroys the very information needed for accurate causal inference. 

These challenges, emergent causality, complex temporality, and non-Euclidean data, are not independent issues to be solved in isolation. They are deeply interrelated and jointly point to a single, underlying problem: modeling reality in complex, adaptive, and dynamic systems. This requires a fundamental rethinking of causality itself, moving away from a static, linear interpretation and towards a dynamic, context-aware, and dynamic process. More profoundly, a novel theory of causality alone would not resolve the problem because, even if the existing SCM would somehow be extended with dynamic causality, the problem of context and non-Euclidean representation would remain unsolved. Instead, a new foundation of causality becomes necessary from which contextual dynamic causal systems can be build upon. 

\newpage

 